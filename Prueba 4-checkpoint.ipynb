{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 4. Analisis de la clasificación de anotaciones patológicas indefinidas de datos adquiridos por MSI de muestras de tejido cancerígeno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación detallada en la memoria del TFG: APLICACION BASADA EN RED NEURONAL PARA DETERMINAR AUTOMATICAMENTE REGIONES CANCERÍGENAS EN MUESTRAS DE TEJIDO DE CÁNCER COLORRECTAL DETERMINADAS POR MSI.\n",
    "\n",
    "Autor: Alejandro Gallar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutor: Pere Ràfols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grado: Ingeniería biomédica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadr as pr\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRead(dataframe):\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for x in dataframe:\n",
    "        ret.append(pr.read_r('C:/Users/Alejandro/Desktop/4.2/TFG/myairbridge-UNJOFrwam/' + x)[None])\n",
    "        i = i + 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_intensities = ['CRC1-4_a$/CRC1-4_a$intensity.rds','CRC1-4_b$/CRC1-4_b$intensity.rds','CRC3-a$/CRC3-a$intensity.rds', \n",
    "         'CRC3-b$/CRC3-b$intensity.rds','CRC4-a$/CRC4-a$intensity.rds','CRC12-b$/CRC12-b$intensity.rds',\n",
    "         'CRC5-a$/CRC5-a$intensity.rds','CRC5-b$/CRC5-b$intensity.rds','CRC6-b$/CRC6-b$intensity.rds','CRC6-a$/CRC6-a$intensity.rds',\n",
    "         'CRC7-a$/CRC7-a$intensity.rds','CRC7-b$/CRC7-b$intensity.rds','CRC8-3_b$/CRC8-3_b$intensity.rds',\n",
    "         'CRC9-b$/CRC9-b$intensity.rds','CRC10-a$/CRC10-a$intensity.rds',\n",
    "         'CRC10-b$/CRC10-b$intensity.rds','CRC11-a$/CRC11-a$intensity.rds','CRC11-b$/CRC11-b$intensity.rds','CRC12-a$/CRC12-a$intensity.rds',\n",
    "         'CRC12-b$/CRC12-b$intensity.rds']\n",
    "\n",
    "paths_rois = ['CRC1-4_a$/CRC1-4_a$ROIs.rds','CRC1-4_b$/CRC1-4_b$ROIs.rds','CRC3-a$/CRC3-a$ROIs.rds', 'CRC3-b$/CRC3-b$ROIs.rds',\n",
    "             'CRC4-a$/CRC4-a$ROIs.rds','CRC12-b$/CRC12-b$ROIs.rds','CRC5-a$/CRC5-a$ROIs.rds','CRC5-b$/CRC5-b$ROIs.rds',\n",
    "             'CRC6-a$/CRC6-a$ROIs.rds', 'CRC6-b$/CRC6-b$ROIs.rds','CRC7-a$/CRC7-a$ROIs.rds','CRC7-b$/CRC7-b$ROIs.rds',\n",
    "             'CRC8-3_b$/CRC8-3_b$ROIs.rds','CRC9-a$/CRC9-a$ROIs.rds','CRC9-b$/CRC9-b$ROIs.rds','CRC10-a$/CRC10-a$ROIs.rds',\n",
    "             'CRC10-b$/CRC10-b$ROIs.rds', 'CRC11-a$/CRC11-a$ROIs.rds','CRC11-b$/CRC11-b$ROIs.rds','CRC12-a$/CRC12-a$ROIs.rds'\n",
    "              ,'CRC12-b$/CRC12-b$ROIs.rds']\n",
    "\n",
    "training = dataRead(paths_intensities)\n",
    "labels = dataRead(paths_rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesado de los datos, separación del set de entramiento y el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset1 = pd.concat(training, ignore_index = True)\n",
    "labels_dataset1 = pd.concat(labels, ignore_index = True)\n",
    "\n",
    "labels_dataset1.columns = ['ROIs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = labels_dataset1.merge(training_dataset1, right_index = True, left_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TorHG = merged[merged['ROIs']=='TorHG']\n",
    "TorHG = TorHG.drop('ROIs',1)\n",
    "TorHG = TorHG.reset_index(drop = True)\n",
    "TorHG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TorPI = merged[merged['ROIs']=='TorPI']\n",
    "TorPI = TorPI.drop('ROIs',1)\n",
    "TorPI = TorPI.reset_index(drop = True)\n",
    "TorPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NLG = merged[merged['ROIs']!='TorPI']\n",
    "NLG = NLG[NLG['ROIs']!='TorHG']\n",
    "NLG = NLG.drop('ROIs',1)\n",
    "NLG = NLG.reset_index(drop = True)\n",
    "NLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(merged['ROIs'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = labels[labels['ROIs']=='T']\n",
    "# s = labels[labels['ROIs']=='PI']\n",
    "labels = labels[labels['ROIs']!='TorPI']\n",
    "labels = labels[labels['ROIs']!='TorHG']\n",
    "# labels = pd.concat([a,s], ignore_index = True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Categorical_to_numerical(labels):\n",
    "    i=0\n",
    "    for x in labels['ROIs']:\n",
    "       \n",
    "        if x == 'N': labels['Code'].array[i]=0\n",
    "        if x == 'LG': labels['Code'].array[i]=1\n",
    "        if x == 'HG': labels['Code'].array[i]=2\n",
    "        if x == 'PI': labels['Code'].array[i]=3\n",
    "        if x == 'T': labels['Code'].array[i]=4\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Code'] = 0\n",
    "Categorical_to_numerical(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = np.array(NLG)\n",
    "dfy = np.array(labels['Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx, dfy = shuffle(dfx, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_dfx = scaler.fit_transform(dfx)\n",
    "scaled_dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caracterización del modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 64, input_shape = (1236,), activation = 'relu'),\n",
    "    Dense(units = 128, activation = 'relu'),\n",
    "    Dense(units = 5, activation = 'softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x = scaled_dfx, y = dfy,validation_split = 0.05,shuffle = True, batch_size = 1000, epochs= 10, verbose =  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scaler.fit_transform(TorHG)\n",
    "scaled_test2 = scaler.fit_transform(TorPI)\n",
    "scaled_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model.predict(x = scaled_test, batch_size = 250, verbose = 0)\n",
    "predictions2 = model.predict(x = scaled_test2, batch_size = 250, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundpred1 = np.argmax(predictions1, axis = -1)\n",
    "roundpred2 = np.argmax(predictions2, axis = -1)\n",
    "roundpred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0\n",
    "LG = 0\n",
    "HG = 0\n",
    "PI = 0\n",
    "T = 0\n",
    "\n",
    "N2 = 0\n",
    "LG2 = 0\n",
    "HG2 = 0\n",
    "PI2 = 0\n",
    "T2 = 0\n",
    "\n",
    "\n",
    "count = 0\n",
    "for x in roundpred1:\n",
    "    if x == 0: N = N + 1\n",
    "    if x == 1: LG = LG + 1\n",
    "    if x == 2: HG = HG + 1\n",
    "    if x == 3: PI = PI + 1\n",
    "    if x == 4: T = T + 1\n",
    "\n",
    "for y in roundpred2:\n",
    "    if y == 0: N2 = N2 + 1\n",
    "    if y == 1: LG2 = LG2 + 1\n",
    "    if y == 2: HG2 = HG2 + 1\n",
    "    if y == 3: PI2 = PI2 + 1\n",
    "    if y == 4: T2 = T2 + 1\n",
    "\n",
    "print('El número de píxeles de la clasificación TorHG ha sido: Normal-', N, 'Grado bajo-', LG, 'Grado alto-',\n",
    "      HG, 'Pseudo invasión-', PI, 'Tumor-', T)\n",
    "print('El número de píxeles de la clasificación TorPI ha sido: Normal-', N2, 'Grado bajo-', LG2, 'Grado alto-',\n",
    "      HG2, 'Pseudo invasión-', PI2, 'Tumor-', T2)\n",
    "        \n",
    "(N, LG, HG, PI, T), (N2, LG2, HG2, PI2, T2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
